{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "import random\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.optimize import minimize\n",
    "from kalman_filter.kalman_filter import (\n",
    "    ConstantVelocityKalmanFilter, FinancialModelKalmanFilter, optimize_kalman_hyperparameters\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pywt  # Ensure you have pywavelets installed for wavelet transforms\n",
    "# from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "# from sklearn.model_selection import ParameterGrid\n",
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Hyperparameter Configurations\n",
    "# -----------------\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "LASSO_PARAM_GRID = {\"logisticregression__C\": np.logspace(-3, 2, 10)}\n",
    "RF_PARAM_GRID = {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 10, 20]}\n",
    "XGB_PARAM_GRID = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.6, 0.8, 1.0]\n",
    "}\n",
    "NN_PARAM_GRID = {\n",
    "    \"hidden_size\": [32, 64, 128],\n",
    "    \"learning_rate\": [0.001, 0.01],\n",
    "    \"num_epochs\": [50, 100]\n",
    "}\n",
    "LSTM_PARAM_GRID = {\n",
    "    \"hidden_size\": [32, 64, 128],\n",
    "    \"num_layers\": [1, 2],\n",
    "    \"learning_rate\": [0.001, 0.01],\n",
    "    \"num_epochs\": [50, 100]\n",
    "}\n",
    "\n",
    "# Kalman Filter Hyperparameters\n",
    "CVKF_PARAM_GRID = [\n",
    "    {\"initial_state\": np.array([0.0]), \"Q_diag\": [q], \"R_diag\": [r]}\n",
    "    for q in [0.01, 0.1, 1.0, 10.0]\n",
    "    for r in [0.01, 0.1, 1.0, 10.0]\n",
    "]\n",
    "FMKF_PARAM_GRID = [\n",
    "    {\"initial_state\": np.array([0.0]), \"Q_diag\": [q], \"R_diag\": [r], \"alpha\": [a], \"beta\": [b]}\n",
    "    for q in [0.01, 0.1, 1.0, 10.0]\n",
    "    for r in [0.01, 0.1, 1.0, 10.0]\n",
    "    for a in [0.4, 0.6, 0.8, 1.0]\n",
    "    for b in [0.05, 0.1, 0.2, 0.4]\n",
    "]\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Utility Functions\n",
    "# -----------------\n",
    "\n",
    "\n",
    "def five_way_split(X, y, train_size=0.5, val1_size=0.15, val2_size=0.1, kalman_size=0.1, test_size=0.15):\n",
    "    \"\"\"Split data into five subsets.\"\"\"\n",
    "    total_len = len(X)\n",
    "\n",
    "    train_len = round(total_len * train_size)\n",
    "    val1_len = round(total_len * val1_size)\n",
    "    val2_len = round(total_len * val2_size)\n",
    "    kalman_len = round(total_len * kalman_size)\n",
    "    test_len = total_len - train_len - val1_len - val2_len - kalman_len\n",
    "\n",
    "    train_idx = range(0, train_len)\n",
    "    val1_idx = range(train_len, train_len + val1_len)\n",
    "    val2_idx = range(train_len + val1_len, train_len + val1_len + val2_len)\n",
    "    kalman_idx = range(train_len + val1_len + val2_len, train_len + val1_len + val2_len + kalman_len)\n",
    "    test_idx = range(train_len + val1_len + val2_len + kalman_len, total_len)\n",
    "\n",
    "    return (\n",
    "        X.iloc[train_idx], X.iloc[val1_idx], X.iloc[val2_idx], X.iloc[kalman_idx], X.iloc[test_idx],\n",
    "        y.iloc[train_idx], y.iloc[val1_idx], y.iloc[val2_idx], y.iloc[kalman_idx], y.iloc[test_idx]\n",
    "    )\n",
    "\n",
    "\n",
    "def optimize_model_hyperparameters(model_fn, param_grid, X_train, y_train, validation_data, n_jobs=1):\n",
    "    \"\"\"\n",
    "    Performs hyperparameter optimization using GridSearchCV.\n",
    "\n",
    "    Args:\n",
    "        model_fn: A callable that returns an instance of the model.\n",
    "        param_grid: Dictionary of hyperparameters to search.\n",
    "        X_train: Training features.\n",
    "        y_train: Training labels.\n",
    "        validation_data: Tuple (X_val, y_val) for validation.\n",
    "        n_jobs: Number of parallel jobs for GridSearchCV.\n",
    "\n",
    "    Returns:\n",
    "        best_model: The best model after GridSearchCV.\n",
    "        best_params: The best parameters from the search.\n",
    "    \"\"\"\n",
    "    model = model_fn()\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=5,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "\n",
    "def calculate_classification_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"\n",
    "    Calculate classification metrics including Accuracy, Precision, Recall, F1, and AUC.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): True labels.\n",
    "        y_pred (array-like): Predicted labels.\n",
    "        y_pred_proba (array-like, optional): Predicted probabilities for the positive class.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of calculated metrics.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    if y_pred_proba is not None:\n",
    "        metrics[\"AUC\"] = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def preprocess_data_with_advanced_features(data_frame, target_column, lag_steps=None, rolling_window=10):\n",
    "    \"\"\"\n",
    "    Preprocess data for time series modeling with advanced feature engineering.\n",
    "    Ensures no data leakage by strictly using past and current data for feature generation.\n",
    "\n",
    "    Args:\n",
    "        data_frame (str): Variable name of loaded pandas data frame.\n",
    "        target_column (str): Target column name.\n",
    "        lag_steps (list): List of lag steps for feature engineering.\n",
    "        rolling_window (int): Window size for rolling features.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Feature DataFrame (X) and target series (y).\n",
    "    \"\"\"\n",
    "    # Load data and parse dates\n",
    "    data = data_frame\n",
    "    data.index = pd.to_datetime(data.index, errors='coerce')  # Ensure index is datetime\n",
    "    assert data.index.is_monotonic_increasing, \"Dataset is not sorted by time.\"\n",
    "\n",
    "    # Fill missing values in the target column\n",
    "    data[target_column] = data[target_column].interpolate(method='linear').bfill()\n",
    "\n",
    "    # Initialize feature storage\n",
    "    features = []\n",
    "    indices = []\n",
    "\n",
    "    for end_idx in range(rolling_window, len(data)):\n",
    "        # Define the current window\n",
    "        window = data.iloc[end_idx - rolling_window:end_idx]\n",
    "\n",
    "        # Compute features for the current timestamp\n",
    "        current_features = {}\n",
    "\n",
    "        # Rolling statistics\n",
    "        signal_cols = [col for col in data.columns if col not in ['patient', 'newtest', 'target', 'event1', 'event2', 'event3', 'event4', 'sleepstage']]  # sleepstage excluded as categorical variable\n",
    "        for col in signal_cols:\n",
    "            current_features[f'{col}_roll_mean'] = window[col].mean()\n",
    "            current_features[f'{col}_roll_std'] = window[col].std()\n",
    "\n",
    "        # Lagged features\n",
    "        if lag_steps:\n",
    "            for lag in lag_steps:\n",
    "                if end_idx - lag >= 0:\n",
    "                    current_features[f'{target_column}_lag{lag}'] = data[target_column].iloc[end_idx - lag]\n",
    "\n",
    "        # Fourier Transform Features\n",
    "        for col in signal_cols:\n",
    "            fourier_transform = np.abs(np.fft.fft(window[col].fillna(0)))\n",
    "            current_features[f'{col}_fft_max'] = np.max(fourier_transform)\n",
    "            current_features[f'{col}_fft_mean'] = np.mean(fourier_transform)\n",
    "\n",
    "        # Wavelet Transform Features\n",
    "        for col in signal_cols:\n",
    "            coeffs = pywt.wavedec(window[col].fillna(0), 'db1', level=3)\n",
    "            current_features[f'{col}_wavelet_approx'] = coeffs[0].mean()\n",
    "            current_features[f'{col}_wavelet_detail1'] = coeffs[1].mean()\n",
    "            current_features[f'{col}_wavelet_detail2'] = coeffs[2].mean()\n",
    "\n",
    "        # Add features and corresponding index\n",
    "        features.append(current_features)\n",
    "        indices.append(data.index[end_idx])\n",
    "\n",
    "    # Convert features to DataFrame\n",
    "    feature_df = pd.DataFrame(features, index=indices)\n",
    "\n",
    "    # Align target values\n",
    "    y = data.loc[feature_df.index, target_column]\n",
    "\n",
    "    return feature_df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Load and Preprocess Data\n",
    "# -----------------\n",
    "\n",
    "def load_and_preprocess_data(dataframe):\n",
    "    # Load and preprocess data with advanced features\n",
    "    X, y = preprocess_data_with_advanced_features(\n",
    "        data_frame=dataframe,\n",
    "        target_column='target',\n",
    "        lag_steps=[1, 2, 3],\n",
    "        rolling_window=10\n",
    "    )\n",
    "\n",
    "    # Perform five-way split\n",
    "    X_train, X_val1, X_val2, X_kalman, X_test, y_train, y_val1, y_val2, y_kalman, y_test = five_way_split(\n",
    "        X, y, train_size=0.5, val1_size=0.15, val2_size=0.05, kalman_size=0.1, test_size=0.2\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val1, X_val2, X_kalman, X_test, y_train, y_val1, y_val2, y_kalman, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with transitions from state 0 → 1 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "master_df = pd.read_stata('./data/processed-data/combined-patient-data-1_00.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group master dataframe by 'patient' and 'newtest' pairs (i.e. by each unique patient data)\n",
    "# Access or initialize each dataframe like: group_dict[('pid100100', 0)]\n",
    "group_dict = {\n",
    "    (val1, val2): data\n",
    "    for (val1, val2), data in master_df.groupby(['patient', 'newtest'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataframes\n",
    "for group_key, subset_df in group_dict.items():\n",
    "    subset_df['target'] = subset_df[['event1', 'event2', 'event3', 'event4']].apply(lambda x: 1 if 'Hypopnea' in x.values or 'Apnea Obstructive' in x.values or 'Apnea Central' in x.values or 'Apnea Mixed' in x.values else 0, axis=1)\n",
    "\n",
    "    cols = list(subset_df.columns)\n",
    "    cols.remove('target')\n",
    "    cols.insert(3, 'target')\n",
    "    subset_df = subset_df[cols]\n",
    "\n",
    "    subset_df.set_index('timess', inplace=True)\n",
    "    \n",
    "    group_dict[group_key] = subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = group_dict[('pid100816', 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    270274\n",
       "1     20110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sample['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = pd.crosstab(y.shift(1), y, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.997215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target         0         1\n",
       "target                    \n",
       "0.0     0.999793  0.000207\n",
       "1.0     0.002785  0.997215"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lagged target variable\n",
    "sample['target_lag1'] = sample['target'].shift(1)\n",
    "\n",
    "# move target_lag1 column to the front\n",
    "cols = list(sample.columns)\n",
    "cols.remove('target_lag1')\n",
    "cols.insert(3, 'target_lag1')\n",
    "sample = sample[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>newtest</th>\n",
       "      <th>target</th>\n",
       "      <th>target_lag1</th>\n",
       "      <th>event1</th>\n",
       "      <th>event2</th>\n",
       "      <th>event3</th>\n",
       "      <th>event4</th>\n",
       "      <th>chin</th>\n",
       "      <th>chin60sma</th>\n",
       "      <th>...</th>\n",
       "      <th>heartratecu</th>\n",
       "      <th>heartratecu60sma</th>\n",
       "      <th>spo2</th>\n",
       "      <th>spo260sma</th>\n",
       "      <th>positioncu</th>\n",
       "      <th>positioncu60sma</th>\n",
       "      <th>snorecu</th>\n",
       "      <th>snorecu60sma</th>\n",
       "      <th>nasalpressure</th>\n",
       "      <th>nasalpressure60sma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timess</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.100</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.44410</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.200</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.27970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.300</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.05683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.400</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.500</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.400</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.429501</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.856905</td>\n",
       "      <td>95.170</td>\n",
       "      <td>95.225191</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-5.615641e-07</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>-0.001838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.500</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.435973</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.858569</td>\n",
       "      <td>95.260</td>\n",
       "      <td>95.225491</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-2.316140e-07</td>\n",
       "      <td>0.15880</td>\n",
       "      <td>-0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.600</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.442446</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.860233</td>\n",
       "      <td>95.200</td>\n",
       "      <td>95.225774</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-3.050416e-06</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>-0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.700</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.446123</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.861897</td>\n",
       "      <td>95.190</td>\n",
       "      <td>95.225774</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>1.229617e-07</td>\n",
       "      <td>0.09409</td>\n",
       "      <td>-0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.800</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.449800</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.863561</td>\n",
       "      <td>95.250</td>\n",
       "      <td>95.225824</td>\n",
       "      <td>-0.002594</td>\n",
       "      <td>-1.502662e-06</td>\n",
       "      <td>0.05956</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290384 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           patient  newtest  target  target_lag1  \\\n",
       "timess                                                             \n",
       "2023-06-28 22:15:00.100  pid100816      0.0       0          NaN   \n",
       "2023-06-28 22:15:00.200  pid100816      0.0       0          0.0   \n",
       "2023-06-28 22:15:00.300  pid100816      0.0       0          0.0   \n",
       "2023-06-28 22:15:00.400  pid100816      0.0       0          0.0   \n",
       "2023-06-28 22:15:00.500  pid100816      0.0       0          0.0   \n",
       "...                            ...      ...     ...          ...   \n",
       "2023-06-29 06:19:59.400  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.500  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.600  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.700  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.800  pid100816      0.0       0          0.0   \n",
       "\n",
       "                                      event1 event2 event3 event4      chin  \\\n",
       "timess                                                                        \n",
       "2023-06-28 22:15:00.100                                           -0.000016   \n",
       "2023-06-28 22:15:00.200                                           -0.000019   \n",
       "2023-06-28 22:15:00.300                                           -0.000049   \n",
       "2023-06-28 22:15:00.400                                           -0.000001   \n",
       "2023-06-28 22:15:00.500                                            0.000003   \n",
       "...                                      ...    ...    ...    ...       ...   \n",
       "2023-06-29 06:19:59.400  Spontaneous Arousal                      -0.000047   \n",
       "2023-06-29 06:19:59.500  Spontaneous Arousal                      -0.000041   \n",
       "2023-06-29 06:19:59.600  Spontaneous Arousal                      -0.000040   \n",
       "2023-06-29 06:19:59.700  Spontaneous Arousal                      -0.000033   \n",
       "2023-06-29 06:19:59.800  Spontaneous Arousal                      -0.000033   \n",
       "\n",
       "                         chin60sma  ... heartratecu  heartratecu60sma  spo2  \\\n",
       "timess                              ...                                       \n",
       "2023-06-28 22:15:00.100        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.200        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.300        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.400        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.500        NaN  ...       22.39               NaN  98.0   \n",
       "...                            ...  ...         ...               ...   ...   \n",
       "2023-06-29 06:19:59.400  -0.000009  ...       74.07         73.429501  98.0   \n",
       "2023-06-29 06:19:59.500  -0.000009  ...       74.07         73.435973  98.0   \n",
       "2023-06-29 06:19:59.600  -0.000010  ...       74.07         73.442446  98.0   \n",
       "2023-06-29 06:19:59.700  -0.000010  ...       74.07         73.446123  98.0   \n",
       "2023-06-29 06:19:59.800  -0.000011  ...       74.07         73.449800  98.0   \n",
       "\n",
       "                         spo260sma  positioncu  positioncu60sma   snorecu  \\\n",
       "timess                                                                      \n",
       "2023-06-28 22:15:00.100        NaN       3.204              NaN  0.001434   \n",
       "2023-06-28 22:15:00.200        NaN       2.838              NaN -0.006409   \n",
       "2023-06-28 22:15:00.300        NaN       2.853              NaN  0.007279   \n",
       "2023-06-28 22:15:00.400        NaN       2.609              NaN -0.002930   \n",
       "2023-06-28 22:15:00.500        NaN       2.533              NaN -0.001022   \n",
       "...                            ...         ...              ...       ...   \n",
       "2023-06-29 06:19:59.400  96.856905      95.170        95.225191  0.000061   \n",
       "2023-06-29 06:19:59.500  96.858569      95.260        95.225491  0.000702   \n",
       "2023-06-29 06:19:59.600  96.860233      95.200        95.225774 -0.000244   \n",
       "2023-06-29 06:19:59.700  96.861897      95.190        95.225774  0.001129   \n",
       "2023-06-29 06:19:59.800  96.863561      95.250        95.225824 -0.002594   \n",
       "\n",
       "                         snorecu60sma  nasalpressure  nasalpressure60sma  \n",
       "timess                                                                    \n",
       "2023-06-28 22:15:00.100           NaN       -0.44410                 NaN  \n",
       "2023-06-28 22:15:00.200           NaN       -0.27970                 NaN  \n",
       "2023-06-28 22:15:00.300           NaN       -0.05683                 NaN  \n",
       "2023-06-28 22:15:00.400           NaN        0.14230                 NaN  \n",
       "2023-06-28 22:15:00.500           NaN        0.21020                 NaN  \n",
       "...                               ...            ...                 ...  \n",
       "2023-06-29 06:19:59.400 -5.615641e-07        0.20000           -0.001838  \n",
       "2023-06-29 06:19:59.500 -2.316140e-07        0.15880           -0.001416  \n",
       "2023-06-29 06:19:59.600 -3.050416e-06        0.11200           -0.000908  \n",
       "2023-06-29 06:19:59.700  1.229617e-07        0.09409           -0.000283  \n",
       "2023-06-29 06:19:59.800 -1.502662e-06        0.05956            0.000399  \n",
       "\n",
       "[290384 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>newtest</th>\n",
       "      <th>target</th>\n",
       "      <th>target_lag1</th>\n",
       "      <th>event1</th>\n",
       "      <th>event2</th>\n",
       "      <th>event3</th>\n",
       "      <th>event4</th>\n",
       "      <th>chin</th>\n",
       "      <th>chin60sma</th>\n",
       "      <th>...</th>\n",
       "      <th>heartratecu</th>\n",
       "      <th>heartratecu60sma</th>\n",
       "      <th>spo2</th>\n",
       "      <th>spo260sma</th>\n",
       "      <th>positioncu</th>\n",
       "      <th>positioncu60sma</th>\n",
       "      <th>snorecu</th>\n",
       "      <th>snorecu60sma</th>\n",
       "      <th>nasalpressure</th>\n",
       "      <th>nasalpressure60sma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timess</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.200</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.27970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.300</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.05683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.400</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.500</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.600</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.400</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.429501</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.856905</td>\n",
       "      <td>95.170</td>\n",
       "      <td>95.225191</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-5.615641e-07</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>-0.001838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.500</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.435973</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.858569</td>\n",
       "      <td>95.260</td>\n",
       "      <td>95.225491</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-2.316140e-07</td>\n",
       "      <td>0.15880</td>\n",
       "      <td>-0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.600</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.442446</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.860233</td>\n",
       "      <td>95.200</td>\n",
       "      <td>95.225774</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-3.050416e-06</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>-0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.700</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.446123</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.861897</td>\n",
       "      <td>95.190</td>\n",
       "      <td>95.225774</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>1.229617e-07</td>\n",
       "      <td>0.09409</td>\n",
       "      <td>-0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.800</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.449800</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.863561</td>\n",
       "      <td>95.250</td>\n",
       "      <td>95.225824</td>\n",
       "      <td>-0.002594</td>\n",
       "      <td>-1.502662e-06</td>\n",
       "      <td>0.05956</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270273 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           patient  newtest  target  target_lag1  \\\n",
       "timess                                                             \n",
       "2023-06-28 22:15:00.200  pid100816      0.0       0          0.0   \n",
       "2023-06-28 22:15:00.300  pid100816      0.0       0          0.0   \n",
       "2023-06-28 22:15:00.400  pid100816      0.0       0          0.0   \n",
       "2023-06-28 22:15:00.500  pid100816      0.0       0          0.0   \n",
       "2023-06-28 22:15:00.600  pid100816      0.0       0          0.0   \n",
       "...                            ...      ...     ...          ...   \n",
       "2023-06-29 06:19:59.400  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.500  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.600  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.700  pid100816      0.0       0          0.0   \n",
       "2023-06-29 06:19:59.800  pid100816      0.0       0          0.0   \n",
       "\n",
       "                                      event1 event2 event3 event4      chin  \\\n",
       "timess                                                                        \n",
       "2023-06-28 22:15:00.200                                           -0.000019   \n",
       "2023-06-28 22:15:00.300                                           -0.000049   \n",
       "2023-06-28 22:15:00.400                                           -0.000001   \n",
       "2023-06-28 22:15:00.500                                            0.000003   \n",
       "2023-06-28 22:15:00.600                                            0.000014   \n",
       "...                                      ...    ...    ...    ...       ...   \n",
       "2023-06-29 06:19:59.400  Spontaneous Arousal                      -0.000047   \n",
       "2023-06-29 06:19:59.500  Spontaneous Arousal                      -0.000041   \n",
       "2023-06-29 06:19:59.600  Spontaneous Arousal                      -0.000040   \n",
       "2023-06-29 06:19:59.700  Spontaneous Arousal                      -0.000033   \n",
       "2023-06-29 06:19:59.800  Spontaneous Arousal                      -0.000033   \n",
       "\n",
       "                         chin60sma  ... heartratecu  heartratecu60sma  spo2  \\\n",
       "timess                              ...                                       \n",
       "2023-06-28 22:15:00.200        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.300        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.400        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.500        NaN  ...       22.39               NaN  98.0   \n",
       "2023-06-28 22:15:00.600        NaN  ...       22.39               NaN  98.0   \n",
       "...                            ...  ...         ...               ...   ...   \n",
       "2023-06-29 06:19:59.400  -0.000009  ...       74.07         73.429501  98.0   \n",
       "2023-06-29 06:19:59.500  -0.000009  ...       74.07         73.435973  98.0   \n",
       "2023-06-29 06:19:59.600  -0.000010  ...       74.07         73.442446  98.0   \n",
       "2023-06-29 06:19:59.700  -0.000010  ...       74.07         73.446123  98.0   \n",
       "2023-06-29 06:19:59.800  -0.000011  ...       74.07         73.449800  98.0   \n",
       "\n",
       "                         spo260sma  positioncu  positioncu60sma   snorecu  \\\n",
       "timess                                                                      \n",
       "2023-06-28 22:15:00.200        NaN       2.838              NaN -0.006409   \n",
       "2023-06-28 22:15:00.300        NaN       2.853              NaN  0.007279   \n",
       "2023-06-28 22:15:00.400        NaN       2.609              NaN -0.002930   \n",
       "2023-06-28 22:15:00.500        NaN       2.533              NaN -0.001022   \n",
       "2023-06-28 22:15:00.600        NaN       2.106              NaN  0.001328   \n",
       "...                            ...         ...              ...       ...   \n",
       "2023-06-29 06:19:59.400  96.856905      95.170        95.225191  0.000061   \n",
       "2023-06-29 06:19:59.500  96.858569      95.260        95.225491  0.000702   \n",
       "2023-06-29 06:19:59.600  96.860233      95.200        95.225774 -0.000244   \n",
       "2023-06-29 06:19:59.700  96.861897      95.190        95.225774  0.001129   \n",
       "2023-06-29 06:19:59.800  96.863561      95.250        95.225824 -0.002594   \n",
       "\n",
       "                         snorecu60sma  nasalpressure  nasalpressure60sma  \n",
       "timess                                                                    \n",
       "2023-06-28 22:15:00.200           NaN       -0.27970                 NaN  \n",
       "2023-06-28 22:15:00.300           NaN       -0.05683                 NaN  \n",
       "2023-06-28 22:15:00.400           NaN        0.14230                 NaN  \n",
       "2023-06-28 22:15:00.500           NaN        0.21020                 NaN  \n",
       "2023-06-28 22:15:00.600           NaN        0.27380                 NaN  \n",
       "...                               ...            ...                 ...  \n",
       "2023-06-29 06:19:59.400 -5.615641e-07        0.20000           -0.001838  \n",
       "2023-06-29 06:19:59.500 -2.316140e-07        0.15880           -0.001416  \n",
       "2023-06-29 06:19:59.600 -3.050416e-06        0.11200           -0.000908  \n",
       "2023-06-29 06:19:59.700  1.229617e-07        0.09409           -0.000283  \n",
       "2023-06-29 06:19:59.800 -1.502662e-06        0.05956            0.000399  \n",
       "\n",
       "[270273 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataset to only observations where previous state of target was 0\n",
    "transition_sample = sample[sample['target_lag1'] == 0]\n",
    "transition_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    270217\n",
       "1        56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_sample['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    270274\n",
       "1     20110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/kjbh4_8964599ypdwfdp5b640000gn/T/ipykernel_1709/4124581745.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transition_sample.drop('target_lag1', axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>newtest</th>\n",
       "      <th>target</th>\n",
       "      <th>event1</th>\n",
       "      <th>event2</th>\n",
       "      <th>event3</th>\n",
       "      <th>event4</th>\n",
       "      <th>chin</th>\n",
       "      <th>chin60sma</th>\n",
       "      <th>sleepstage</th>\n",
       "      <th>heartratecu</th>\n",
       "      <th>heartratecu60sma</th>\n",
       "      <th>spo2</th>\n",
       "      <th>spo260sma</th>\n",
       "      <th>positioncu</th>\n",
       "      <th>positioncu60sma</th>\n",
       "      <th>snorecu</th>\n",
       "      <th>snorecu60sma</th>\n",
       "      <th>nasalpressure</th>\n",
       "      <th>nasalpressure60sma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timess</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.200</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.27970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.300</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.05683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.400</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.500</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 22:15:00.600</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.400</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>N2</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.429501</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.856905</td>\n",
       "      <td>95.170</td>\n",
       "      <td>95.225191</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-5.615641e-07</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>-0.001838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.500</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>N2</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.435973</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.858569</td>\n",
       "      <td>95.260</td>\n",
       "      <td>95.225491</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-2.316140e-07</td>\n",
       "      <td>0.15880</td>\n",
       "      <td>-0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.600</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>N2</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.442446</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.860233</td>\n",
       "      <td>95.200</td>\n",
       "      <td>95.225774</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-3.050416e-06</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>-0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.700</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>N2</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.446123</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.861897</td>\n",
       "      <td>95.190</td>\n",
       "      <td>95.225774</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>1.229617e-07</td>\n",
       "      <td>0.09409</td>\n",
       "      <td>-0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 06:19:59.800</th>\n",
       "      <td>pid100816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spontaneous Arousal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>N2</td>\n",
       "      <td>74.07</td>\n",
       "      <td>73.449800</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.863561</td>\n",
       "      <td>95.250</td>\n",
       "      <td>95.225824</td>\n",
       "      <td>-0.002594</td>\n",
       "      <td>-1.502662e-06</td>\n",
       "      <td>0.05956</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270273 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           patient  newtest  target               event1  \\\n",
       "timess                                                                     \n",
       "2023-06-28 22:15:00.200  pid100816      0.0       0                        \n",
       "2023-06-28 22:15:00.300  pid100816      0.0       0                        \n",
       "2023-06-28 22:15:00.400  pid100816      0.0       0                        \n",
       "2023-06-28 22:15:00.500  pid100816      0.0       0                        \n",
       "2023-06-28 22:15:00.600  pid100816      0.0       0                        \n",
       "...                            ...      ...     ...                  ...   \n",
       "2023-06-29 06:19:59.400  pid100816      0.0       0  Spontaneous Arousal   \n",
       "2023-06-29 06:19:59.500  pid100816      0.0       0  Spontaneous Arousal   \n",
       "2023-06-29 06:19:59.600  pid100816      0.0       0  Spontaneous Arousal   \n",
       "2023-06-29 06:19:59.700  pid100816      0.0       0  Spontaneous Arousal   \n",
       "2023-06-29 06:19:59.800  pid100816      0.0       0  Spontaneous Arousal   \n",
       "\n",
       "                        event2 event3 event4      chin  chin60sma sleepstage  \\\n",
       "timess                                                                         \n",
       "2023-06-28 22:15:00.200                      -0.000019        NaN          W   \n",
       "2023-06-28 22:15:00.300                      -0.000049        NaN          W   \n",
       "2023-06-28 22:15:00.400                      -0.000001        NaN          W   \n",
       "2023-06-28 22:15:00.500                       0.000003        NaN          W   \n",
       "2023-06-28 22:15:00.600                       0.000014        NaN          W   \n",
       "...                        ...    ...    ...       ...        ...        ...   \n",
       "2023-06-29 06:19:59.400                      -0.000047  -0.000009         N2   \n",
       "2023-06-29 06:19:59.500                      -0.000041  -0.000009         N2   \n",
       "2023-06-29 06:19:59.600                      -0.000040  -0.000010         N2   \n",
       "2023-06-29 06:19:59.700                      -0.000033  -0.000010         N2   \n",
       "2023-06-29 06:19:59.800                      -0.000033  -0.000011         N2   \n",
       "\n",
       "                         heartratecu  heartratecu60sma  spo2  spo260sma  \\\n",
       "timess                                                                    \n",
       "2023-06-28 22:15:00.200        22.39               NaN  98.0        NaN   \n",
       "2023-06-28 22:15:00.300        22.39               NaN  98.0        NaN   \n",
       "2023-06-28 22:15:00.400        22.39               NaN  98.0        NaN   \n",
       "2023-06-28 22:15:00.500        22.39               NaN  98.0        NaN   \n",
       "2023-06-28 22:15:00.600        22.39               NaN  98.0        NaN   \n",
       "...                              ...               ...   ...        ...   \n",
       "2023-06-29 06:19:59.400        74.07         73.429501  98.0  96.856905   \n",
       "2023-06-29 06:19:59.500        74.07         73.435973  98.0  96.858569   \n",
       "2023-06-29 06:19:59.600        74.07         73.442446  98.0  96.860233   \n",
       "2023-06-29 06:19:59.700        74.07         73.446123  98.0  96.861897   \n",
       "2023-06-29 06:19:59.800        74.07         73.449800  98.0  96.863561   \n",
       "\n",
       "                         positioncu  positioncu60sma   snorecu  snorecu60sma  \\\n",
       "timess                                                                         \n",
       "2023-06-28 22:15:00.200       2.838              NaN -0.006409           NaN   \n",
       "2023-06-28 22:15:00.300       2.853              NaN  0.007279           NaN   \n",
       "2023-06-28 22:15:00.400       2.609              NaN -0.002930           NaN   \n",
       "2023-06-28 22:15:00.500       2.533              NaN -0.001022           NaN   \n",
       "2023-06-28 22:15:00.600       2.106              NaN  0.001328           NaN   \n",
       "...                             ...              ...       ...           ...   \n",
       "2023-06-29 06:19:59.400      95.170        95.225191  0.000061 -5.615641e-07   \n",
       "2023-06-29 06:19:59.500      95.260        95.225491  0.000702 -2.316140e-07   \n",
       "2023-06-29 06:19:59.600      95.200        95.225774 -0.000244 -3.050416e-06   \n",
       "2023-06-29 06:19:59.700      95.190        95.225774  0.001129  1.229617e-07   \n",
       "2023-06-29 06:19:59.800      95.250        95.225824 -0.002594 -1.502662e-06   \n",
       "\n",
       "                         nasalpressure  nasalpressure60sma  \n",
       "timess                                                      \n",
       "2023-06-28 22:15:00.200       -0.27970                 NaN  \n",
       "2023-06-28 22:15:00.300       -0.05683                 NaN  \n",
       "2023-06-28 22:15:00.400        0.14230                 NaN  \n",
       "2023-06-28 22:15:00.500        0.21020                 NaN  \n",
       "2023-06-28 22:15:00.600        0.27380                 NaN  \n",
       "...                                ...                 ...  \n",
       "2023-06-29 06:19:59.400        0.20000           -0.001838  \n",
       "2023-06-29 06:19:59.500        0.15880           -0.001416  \n",
       "2023-06-29 06:19:59.600        0.11200           -0.000908  \n",
       "2023-06-29 06:19:59.700        0.09409           -0.000283  \n",
       "2023-06-29 06:19:59.800        0.05956            0.000399  \n",
       "\n",
       "[270273 rows x 20 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop column target_lag1 from transition_sample\n",
    "transition_sample.drop('target_lag1', axis=1, inplace=True)\n",
    "transition_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/kjbh4_8964599ypdwfdp5b640000gn/T/ipykernel_1709/3623729679.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[target_column] = data[target_column].interpolate(method='linear').bfill()\n"
     ]
    }
   ],
   "source": [
    "Xy_before_dropnan = load_and_preprocess_data(transition_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN from Xs and corresponding rows from ys\n",
    "def drop_nan_from_Xy(X_train, X_val1, X_val2, X_kalman, X_test, y_train, y_val1, y_val2, y_kalman, y_test):\n",
    "    # Drop rows with NaN from X\n",
    "    X_train_cleaned = X_train.dropna()\n",
    "    X_val1_cleaned = X_val1.dropna()\n",
    "    X_val2_cleaned = X_val2.dropna()\n",
    "    X_kalman_cleaned = X_kalman.dropna()\n",
    "    X_test_cleaned = X_test.dropna()\n",
    "    \n",
    "    # Drop corresponding rows from y\n",
    "    y_train_cleaned = y_train[X_train_cleaned.index]\n",
    "    y_val1_cleaned = y_val1[X_val1_cleaned.index]\n",
    "    y_val2_cleaned = y_val2[X_val2_cleaned.index]\n",
    "    y_kalman_cleaned = y_kalman[X_kalman_cleaned.index]\n",
    "    y_test_cleaned = y_test[X_test_cleaned.index]\n",
    "    \n",
    "    return (\n",
    "        X_train_cleaned, X_val1_cleaned, X_val2_cleaned, X_kalman_cleaned, X_test_cleaned,\n",
    "        y_train_cleaned, y_val1_cleaned, y_val2_cleaned, y_kalman_cleaned, y_test_cleaned\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val1, X_val2, X_kalman, X_test, y_train, y_val1, y_val2, y_kalman, y_test = drop_nan_from_Xy(*Xy_before_dropnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics: {'Accuracy': 0.7588847982535659, 'Precision': 0.0, 'Recall': 0.0, 'F1': 0.0, 'AUC': np.float64(0.3924733570159858)}\n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# Logistic Regression\n",
    "# -----------------\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logisticregression', LogisticRegression(class_weight='balanced', max_iter=2000))  # Handle class imbalance\n",
    "])\n",
    "log_reg_grid = GridSearchCV(log_reg_pipeline, LASSO_PARAM_GRID, cv=5, scoring='roc_auc')\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "log_reg_model = log_reg_grid.best_estimator_\n",
    "\n",
    "log_reg_preds = log_reg_model.predict(X_test)\n",
    "log_reg_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, log_reg_preds),\n",
    "    \"Precision\": precision_score(y_test, log_reg_preds, zero_division=0),  # Avoid warning\n",
    "    \"Recall\": recall_score(y_test, log_reg_preds, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, log_reg_preds, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, log_reg_model.predict_proba(X_test)[:, 1])\n",
    "}\n",
    "print(\"Logistic Regression Metrics:\", log_reg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([41025, 13028]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(log_reg_preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics: {'Accuracy': 0.9999074981962148, 'Precision': 0.0, 'Recall': 0.0, 'F1': 0.0, 'AUC': np.float64(0.44565756364712844)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heewon/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# Random Forest\n",
    "# -----------------\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('randomforest', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'))  # Handle class imbalance\n",
    "])\n",
    "rf_param_grid = {\n",
    "    \"randomforest__n_estimators\": [50, 100, 200],  # Prefixed by 'randomforest__'\n",
    "    \"randomforest__max_depth\": [None, 10, 20]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_pipeline, rf_param_grid, cv=5, scoring='roc_auc')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, rf_preds),\n",
    "    \"Precision\": precision_score(y_test, rf_preds),\n",
    "    \"Recall\": recall_score(y_test, rf_preds),\n",
    "    \"F1\": f1_score(y_test, rf_preds),\n",
    "    \"AUC\": roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "}\n",
    "print(\"Random Forest Metrics:\", rf_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([54053]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rf_preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Metrics: {'Accuracy': 0.9999074981962148, 'Precision': 0.0, 'Recall': 0.0, 'F1': 0.0, 'AUC': np.float64(0.4754662522202487)}\n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# XGBoost\n",
    "# -----------------\n",
    "# Define the pipeline\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Prefix all hyperparameters for 'xgb' step with 'xgb__'\n",
    "xgb_param_grid = {\n",
    "    \"xgb__n_estimators\": [50, 100, 200],\n",
    "    \"xgb__max_depth\": [3, 5, 7],\n",
    "    \"xgb__learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"xgb__subsample\": [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "xgb_grid = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=5, scoring='roc_auc')\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "xgb_model = xgb_grid.best_estimator_\n",
    "\n",
    "# Predictions and metrics\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "xgb_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, xgb_preds),\n",
    "    \"Precision\": precision_score(y_test, xgb_preds, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, xgb_preds, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, xgb_preds, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, 1])\n",
    "}\n",
    "print(\"XGBoost Metrics:\", xgb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([54053]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(xgb_preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing batch2 (without 18 new format data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "master_df = pd.read_stata('./data/processed-data/combined-patient-data-2_00.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group master dataframe by 'patient' and 'newtest' pairs (i.e. by each unique patient data)\n",
    "# Access or initialize each dataframe like: group_dict[('pid100100', 0)]\n",
    "group_dict = {\n",
    "    (val1, val2): data\n",
    "    for (val1, val2), data in master_df.groupby(['patient', 'newtest'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataframes\n",
    "for group_key, subset_df in group_dict.items():\n",
    "    subset_df['target'] = subset_df[['event1', 'event2', 'event3', 'event4']].apply(lambda x: 1 if 'Hypopnea' in x.values or 'Apnea Obstructive' in x.values or 'Apnea Central' in x.values or 'Apnea Mixed' in x.values else 0, axis=1)\n",
    "\n",
    "    cols = list(subset_df.columns)\n",
    "    cols.remove('target')\n",
    "    cols.insert(3, 'target')\n",
    "    subset_df = subset_df[cols]\n",
    "\n",
    "    subset_df.set_index('timess', inplace=True)\n",
    "    \n",
    "    group_dict[group_key] = subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for ideal patient data\n",
    "def is_ideal_patient(patient_df):\n",
    "    X, y = preprocess_data_with_advanced_features(\n",
    "        data_frame=patient_df,\n",
    "        target_column='target',\n",
    "        lag_steps=[1, 2, 3],\n",
    "        rolling_window=10\n",
    "    )\n",
    "\n",
    "    # Perform five-way split\n",
    "    X_train, X_val1, X_val2, X_kalman, X_test, y_train, y_val1, y_val2, y_kalman, y_test = five_way_split(\n",
    "        X, y, train_size=0.5, val1_size=0.15, val2_size=0.05, kalman_size=0.1, test_size=0.2\n",
    "    )\n",
    "    \n",
    "    # Check if all y split components have OSA event occurance (i.e. target = 1)\n",
    "    if y_train.sum() > 0 and y_val1.sum() > 0 and y_val2.sum() > 0 and y_kalman.sum() > 0 and y_test.sum() > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of ideal patients\n",
    "ideal_patients = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Ideal patient data: ('pid101262', np.int32(0))\n",
      "#1 Ideal patient data: ('pid103779', np.int32(0))\n"
     ]
    }
   ],
   "source": [
    "# Check for ideal patients in batches (start, end inclusive range)\n",
    "start = 0\n",
    "end = 1\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(group_dict.items()):\n",
    "    if start <= i <= end:\n",
    "        if is_ideal_patient(subset_df):\n",
    "            print(f\"#{i} Ideal patient data: {group_key}\")\n",
    "            ideal_patients.append(group_key)\n",
    "        else:\n",
    "            print(f\"#{i} Not ideal: {group_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2 Ideal patient data: ('pid103834', np.int32(0))\n",
      "#3 Not ideal: ('pid104223', np.int32(0))\n",
      "#4 Ideal patient data: ('pid105066', np.int32(0))\n",
      "#5 Not ideal: ('pid106588', np.int32(0))\n",
      "#6 Ideal patient data: ('pid109223', np.int32(0))\n",
      "#7 Not ideal: ('pid109592', np.int32(0))\n",
      "#8 Ideal patient data: ('pid109678', np.int32(0))\n",
      "#9 Not ideal: ('pid110546', np.int32(0))\n",
      "#10 Not ideal: ('pid112297', np.int32(0))\n"
     ]
    }
   ],
   "source": [
    "# Check for ideal patients in batches (start, end inclusive range)\n",
    "start = 2\n",
    "end = 10\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(group_dict.items()):\n",
    "    if start <= i <= end:\n",
    "        if is_ideal_patient(subset_df):\n",
    "            print(f\"#{i} Ideal patient data: {group_key}\")\n",
    "            ideal_patients.append(group_key)\n",
    "        else:\n",
    "            print(f\"#{i} Not ideal: {group_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#11 Ideal patient data: ('pid114718', np.int32(0))\n",
      "#12 Ideal patient data: ('pid120645', np.int32(0))\n",
      "#13 Not ideal: ('pid125847', np.int32(0))\n",
      "#14 Ideal patient data: ('pid126099', np.int32(0))\n",
      "#15 Ideal patient data: ('pid134464', np.int32(0))\n",
      "#16 Not ideal: ('pid137169', np.int32(0))\n",
      "#17 Ideal patient data: ('pid137677', np.int32(0))\n",
      "#18 Ideal patient data: ('pid137677', np.int32(1))\n",
      "#19 Ideal patient data: ('pid150632', np.int32(0))\n",
      "#20 Ideal patient data: ('pid158450', np.int32(0))\n",
      "#21 Ideal patient data: ('pid160007', np.int32(0))\n",
      "#22 Ideal patient data: ('pid164094', np.int32(0))\n",
      "#23 Ideal patient data: ('pid175945', np.int32(0))\n",
      "#24 Ideal patient data: ('pid176527', np.int32(0))\n",
      "#25 Ideal patient data: ('pid191990', np.int32(0))\n",
      "#26 Ideal patient data: ('pid195939', np.int32(0))\n",
      "#27 Ideal patient data: ('pid206054', np.int32(0))\n",
      "#28 Ideal patient data: ('pid206255', np.int32(0))\n",
      "#29 Ideal patient data: ('pid217117', np.int32(0))\n",
      "#30 Ideal patient data: ('pid219574', np.int32(0))\n"
     ]
    }
   ],
   "source": [
    "# Check for ideal patients in batches (start, end inclusive range)\n",
    "start = 11\n",
    "end = 30\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(group_dict.items()):\n",
    "    if start <= i <= end:\n",
    "        if is_ideal_patient(subset_df):\n",
    "            print(f\"#{i} Ideal patient data: {group_key}\")\n",
    "            ideal_patients.append(group_key)\n",
    "        else:\n",
    "            print(f\"#{i} Not ideal: {group_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#31 Ideal patient data: ('pid219977', np.int32(0))\n",
      "#32 Ideal patient data: ('pid222375', np.int32(0))\n",
      "#33 Not ideal: ('pid227439', np.int32(0))\n",
      "#34 Ideal patient data: ('pid236528', np.int32(0))\n",
      "#35 Ideal patient data: ('pid237530', np.int32(0))\n",
      "#36 Ideal patient data: ('pid249760', np.int32(0))\n",
      "#37 Not ideal: ('pid253204', np.int32(1))\n",
      "#38 Not ideal: ('pid253204', np.int32(2))\n",
      "#39 Ideal patient data: ('pid258053', np.int32(0))\n",
      "#40 Ideal patient data: ('pid261581', np.int32(0))\n"
     ]
    }
   ],
   "source": [
    "# Check for ideal patients in batches (start, end inclusive range)\n",
    "start = 31\n",
    "end = 40\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(group_dict.items()):\n",
    "    if start <= i <= end:\n",
    "        if is_ideal_patient(subset_df):\n",
    "            print(f\"#{i} Ideal patient data: {group_key}\")\n",
    "            ideal_patients.append(group_key)\n",
    "        else:\n",
    "            print(f\"#{i} Not ideal: {group_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#41 Ideal patient data: ('pid262080', np.int32(0))\n",
      "#42 Ideal patient data: ('pid262752', np.int32(0))\n",
      "#43 Not ideal: ('pid272598', np.int32(1))\n",
      "#44 Ideal patient data: ('pid274397', np.int32(0))\n",
      "#45 Not ideal: ('pid277709', np.int32(0))\n",
      "#46 Not ideal: ('pid277709', np.int32(1))\n",
      "#47 Ideal patient data: ('pid284565', np.int32(0))\n",
      "#48 Not ideal: ('pid300325', np.int32(0))\n",
      "#49 Ideal patient data: ('pid301854', np.int32(0))\n",
      "#50 Not ideal: ('pid309011', np.int32(0))\n",
      "#51 Ideal patient data: ('pid309416', np.int32(0))\n",
      "#52 Not ideal: ('pid311293', np.int32(0))\n",
      "#53 Ideal patient data: ('pid318031', np.int32(0))\n",
      "#54 Ideal patient data: ('pid318257', np.int32(0))\n",
      "#55 Ideal patient data: ('pid322199', np.int32(0))\n",
      "#56 Not ideal: ('pid322272', np.int32(0))\n",
      "#57 Ideal patient data: ('pid322712', np.int32(0))\n",
      "#58 Ideal patient data: ('pid343238', np.int32(0))\n",
      "#59 Ideal patient data: ('pid347862', np.int32(0))\n",
      "#60 Not ideal: ('pid364065', np.int32(0))\n"
     ]
    }
   ],
   "source": [
    "# Check for ideal patients in batches (start, end inclusive range)\n",
    "start = 41\n",
    "end = 60\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(group_dict.items()):\n",
    "    if start <= i <= end:\n",
    "        if is_ideal_patient(subset_df):\n",
    "            print(f\"#{i} Ideal patient data: {group_key}\")\n",
    "            ideal_patients.append(group_key)\n",
    "        else:\n",
    "            print(f\"#{i} Not ideal: {group_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#61 Not ideal: ('pid364822', np.int32(0))\n",
      "#62 Ideal patient data: ('pid376450', np.int32(0))\n",
      "#63 Ideal patient data: ('pid380683', np.int32(0))\n",
      "#64 Ideal patient data: ('pid385394', np.int32(0))\n",
      "#65 Not ideal: ('pid390398', np.int32(0))\n",
      "#66 Not ideal: ('pid390398', np.int32(1))\n",
      "#67 Ideal patient data: ('pid397357', np.int32(0))\n",
      "#68 Ideal patient data: ('pid399459', np.int32(0))\n",
      "#69 Ideal patient data: ('pid399599', np.int32(0))\n",
      "#70 Ideal patient data: ('pid402744', np.int32(0))\n",
      "#71 Ideal patient data: ('pid405345', np.int32(0))\n",
      "#72 Ideal patient data: ('pid411960', np.int32(0))\n",
      "#73 Not ideal: ('pid412118', np.int32(0))\n",
      "#74 Ideal patient data: ('pid413509', np.int32(0))\n",
      "#75 Not ideal: ('pid414678', np.int32(0))\n",
      "#76 Ideal patient data: ('pid423368', np.int32(0))\n",
      "#77 Ideal patient data: ('pid437817', np.int32(0))\n",
      "#78 Ideal patient data: ('pid438399', np.int32(0))\n",
      "#79 Ideal patient data: ('pid438399', np.int32(1))\n",
      "#80 Ideal patient data: ('pid446552', np.int32(0))\n",
      "#81 Not ideal: ('pid453054', np.int32(0))\n",
      "#82 Ideal patient data: ('pid457470', np.int32(0))\n",
      "#83 Ideal patient data: ('pid459222', np.int32(0))\n",
      "#84 Ideal patient data: ('pid459539', np.int32(0))\n",
      "#85 Ideal patient data: ('pid478000', np.int32(0))\n",
      "#86 Ideal patient data: ('pid486831', np.int32(0))\n",
      "#87 Ideal patient data: ('pid488552', np.int32(0))\n",
      "#88 Ideal patient data: ('pid488908', np.int32(0))\n",
      "#89 Ideal patient data: ('pid489460', np.int32(0))\n",
      "#90 Not ideal: ('pid491252', np.int32(0))\n",
      "#91 Ideal patient data: ('pid493030', np.int32(0))\n",
      "#92 Ideal patient data: ('pid506431', np.int32(0))\n",
      "#93 Ideal patient data: ('pid507691', np.int32(0))\n",
      "#94 Ideal patient data: ('pid517112', np.int32(0))\n",
      "#95 Ideal patient data: ('pid518029', np.int32(0))\n",
      "#96 Ideal patient data: ('pid518445', np.int32(0))\n",
      "#97 Ideal patient data: ('pid525057', np.int32(0))\n",
      "#98 Ideal patient data: ('pid525159', np.int32(0))\n",
      "#99 Not ideal: ('pid526278', np.int32(0))\n",
      "#100 Ideal patient data: ('pid529623', np.int32(0))\n"
     ]
    }
   ],
   "source": [
    "# Check for ideal patients in batches (start, end inclusive range)\n",
    "start = 61\n",
    "end = 100\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(group_dict.items()):\n",
    "    if start <= i <= end:\n",
    "        if is_ideal_patient(subset_df):\n",
    "            print(f\"#{i} Ideal patient data: {group_key}\")\n",
    "            ideal_patients.append(group_key)\n",
    "        else:\n",
    "            print(f\"#{i} Not ideal: {group_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#101 Ideal patient data: ('pid533327', np.int32(0))\n",
      "#102 Ideal patient data: ('pid534289', np.int32(0))\n",
      "#103 Ideal patient data: ('pid535238', np.int32(0))\n",
      "#104 Not ideal: ('pid538608', np.int32(0))\n",
      "#105 Not ideal: ('pid544735', np.int32(0))\n",
      "#106 Ideal patient data: ('pid545397', np.int32(0))\n",
      "#107 Ideal patient data: ('pid549202', np.int32(0))\n",
      "#108 Ideal patient data: ('pid552164', np.int32(0))\n",
      "#109 Not ideal: ('pid553262', np.int32(0))\n",
      "#110 Ideal patient data: ('pid553961', np.int32(0))\n",
      "#111 Ideal patient data: ('pid557844', np.int32(0))\n",
      "#112 Ideal patient data: ('pid557944', np.int32(0))\n",
      "#113 Ideal patient data: ('pid563193', np.int32(0))\n",
      "#114 Ideal patient data: ('pid576344', np.int32(0))\n",
      "#115 Ideal patient data: ('pid577183', np.int32(0))\n",
      "#116 Not ideal: ('pid578645', np.int32(0))\n",
      "#117 Ideal patient data: ('pid584940', np.int32(0))\n",
      "#118 Not ideal: ('pid585119', np.int32(0))\n",
      "#119 Ideal patient data: ('pid585927', np.int32(0))\n",
      "#120 Ideal patient data: ('pid587374', np.int32(0))\n",
      "#121 Ideal patient data: ('pid594818', np.int32(0))\n",
      "#122 Ideal patient data: ('pid610408', np.int32(0))\n",
      "#123 Ideal patient data: ('pid618237', np.int32(0))\n",
      "#124 Ideal patient data: ('pid619900', np.int32(0))\n",
      "#125 Ideal patient data: ('pid619936', np.int32(0))\n",
      "#126 Ideal patient data: ('pid624067', np.int32(0))\n",
      "#127 Not ideal: ('pid625745', np.int32(0))\n",
      "#128 Not ideal: ('pid625746', np.int32(0))\n",
      "#129 Not ideal: ('pid628930', np.int32(0))\n",
      "#130 Not ideal: ('pid632838', np.int32(0))\n",
      "#131 Ideal patient data: ('pid634825', np.int32(0))\n",
      "#132 Ideal patient data: ('pid638245', np.int32(0))\n",
      "#133 Ideal patient data: ('pid639011', np.int32(0))\n",
      "#134 Not ideal: ('pid639012', np.int32(0))\n",
      "#135 Not ideal: ('pid640283', np.int32(0))\n",
      "#136 Not ideal: ('pid641103', np.int32(0))\n",
      "#137 Not ideal: ('pid641298', np.int32(0))\n",
      "#138 Ideal patient data: ('pid641633', np.int32(0))\n",
      "#139 Not ideal: ('pid642728', np.int32(0))\n",
      "#140 Not ideal: ('pid647372', np.int32(0))\n",
      "#141 Ideal patient data: ('pid655066', np.int32(0))\n",
      "#142 Ideal patient data: ('pid655066', np.int32(1))\n",
      "#143 Not ideal: ('pid660566', np.int32(0))\n",
      "#144 Ideal patient data: ('pid666595', np.int32(0))\n",
      "#145 Ideal patient data: ('pid674288', np.int32(0))\n",
      "#146 Ideal patient data: ('pid675210', np.int32(0))\n",
      "#147 Ideal patient data: ('pid675443', np.int32(0))\n",
      "#148 Not ideal: ('pid675795', np.int32(0))\n",
      "#149 Ideal patient data: ('pid675799', np.int32(0))\n",
      "#150 Not ideal: ('pid677721', np.int32(0))\n",
      "#151 Ideal patient data: ('pid679283', np.int32(0))\n",
      "#152 Not ideal: ('pid681689', np.int32(0))\n",
      "#153 Ideal patient data: ('pid682251', np.int32(0))\n",
      "#154 Not ideal: ('pid683940', np.int32(0))\n"
     ]
    }
   ],
   "source": [
    "# Check for ideal patients in batches (start, end inclusive range)\n",
    "start = 101\n",
    "end = 155\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(group_dict.items()):\n",
    "    if start <= i <= end:\n",
    "        if is_ideal_patient(subset_df):\n",
    "            print(f\"#{i} Ideal patient data: {group_key}\")\n",
    "            ideal_patients.append(group_key)\n",
    "        else:\n",
    "            print(f\"#{i} Not ideal: {group_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pid101262', 0),\n",
       " ('pid103779', 0),\n",
       " ('pid103834', 0),\n",
       " ('pid105066', 0),\n",
       " ('pid109223', 0),\n",
       " ('pid109678', 0),\n",
       " ('pid114718', 0),\n",
       " ('pid120645', 0),\n",
       " ('pid126099', 0),\n",
       " ('pid134464', 0),\n",
       " ('pid137677', 0),\n",
       " ('pid137677', 1),\n",
       " ('pid150632', 0),\n",
       " ('pid158450', 0),\n",
       " ('pid160007', 0),\n",
       " ('pid164094', 0),\n",
       " ('pid175945', 0),\n",
       " ('pid176527', 0),\n",
       " ('pid191990', 0),\n",
       " ('pid195939', 0),\n",
       " ('pid206054', 0),\n",
       " ('pid206255', 0),\n",
       " ('pid217117', 0),\n",
       " ('pid219574', 0),\n",
       " ('pid219977', 0),\n",
       " ('pid222375', 0),\n",
       " ('pid236528', 0),\n",
       " ('pid237530', 0),\n",
       " ('pid249760', 0),\n",
       " ('pid258053', 0),\n",
       " ('pid261581', 0),\n",
       " ('pid262080', 0),\n",
       " ('pid262752', 0),\n",
       " ('pid274397', 0),\n",
       " ('pid284565', 0),\n",
       " ('pid301854', 0),\n",
       " ('pid309416', 0),\n",
       " ('pid318031', 0),\n",
       " ('pid318257', 0),\n",
       " ('pid322199', 0),\n",
       " ('pid322712', 0),\n",
       " ('pid343238', 0),\n",
       " ('pid347862', 0),\n",
       " ('pid376450', 0),\n",
       " ('pid380683', 0),\n",
       " ('pid385394', 0),\n",
       " ('pid397357', 0),\n",
       " ('pid399459', 0),\n",
       " ('pid399599', 0),\n",
       " ('pid402744', 0),\n",
       " ('pid405345', 0),\n",
       " ('pid411960', 0),\n",
       " ('pid413509', 0),\n",
       " ('pid423368', 0),\n",
       " ('pid437817', 0),\n",
       " ('pid438399', 0),\n",
       " ('pid438399', 1),\n",
       " ('pid446552', 0),\n",
       " ('pid457470', 0),\n",
       " ('pid459222', 0),\n",
       " ('pid459539', 0),\n",
       " ('pid478000', 0),\n",
       " ('pid486831', 0),\n",
       " ('pid488552', 0),\n",
       " ('pid488908', 0),\n",
       " ('pid489460', 0),\n",
       " ('pid493030', 0),\n",
       " ('pid506431', 0),\n",
       " ('pid507691', 0),\n",
       " ('pid517112', 0),\n",
       " ('pid518029', 0),\n",
       " ('pid518445', 0),\n",
       " ('pid525057', 0),\n",
       " ('pid525159', 0),\n",
       " ('pid529623', 0),\n",
       " ('pid533327', 0),\n",
       " ('pid534289', 0),\n",
       " ('pid535238', 0),\n",
       " ('pid545397', 0),\n",
       " ('pid549202', 0),\n",
       " ('pid552164', 0),\n",
       " ('pid553961', 0),\n",
       " ('pid557844', 0),\n",
       " ('pid557944', 0),\n",
       " ('pid563193', 0),\n",
       " ('pid576344', 0),\n",
       " ('pid577183', 0),\n",
       " ('pid584940', 0),\n",
       " ('pid585927', 0),\n",
       " ('pid587374', 0),\n",
       " ('pid594818', 0),\n",
       " ('pid610408', 0),\n",
       " ('pid618237', 0),\n",
       " ('pid619900', 0),\n",
       " ('pid619936', 0),\n",
       " ('pid624067', 0),\n",
       " ('pid634825', 0),\n",
       " ('pid638245', 0),\n",
       " ('pid639011', 0),\n",
       " ('pid641633', 0),\n",
       " ('pid655066', 0),\n",
       " ('pid655066', 1),\n",
       " ('pid666595', 0),\n",
       " ('pid674288', 0),\n",
       " ('pid675210', 0),\n",
       " ('pid675443', 0),\n",
       " ('pid675799', 0),\n",
       " ('pid679283', 0),\n",
       " ('pid682251', 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "0.7032258064516129\n"
     ]
    }
   ],
   "source": [
    "print(len(ideal_patients))\n",
    "print(len(ideal_patients) / 155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ideal = pd.DataFrame(ideal_patients, columns=['patient', 'newtest'])\n",
    "df_ideal.to_csv('./data/ideal_patients_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ideal_group_dict from group_dict using ideal_patients\n",
    "ideal_patients = pd.read_csv('./data/ideal_patients_2.csv')\n",
    "ideal_patients = list(ideal_patients.itertuples(index=False, name=None))\n",
    "\n",
    "ideal_group_dict = {\n",
    "    (val1, val2): group_dict[(val1, val2)]\n",
    "    for (val1, val2) in ideal_patients\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with ideal pid101262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_before_dropnan = load_and_preprocess_data(ideal_group_dict[('pid101262', 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN from Xs and corresponding rows from ys\n",
    "def drop_nan_from_Xy(X_train, X_val1, X_val2, X_kalman, X_test, y_train, y_val1, y_val2, y_kalman, y_test):\n",
    "    # Drop rows with NaN from X\n",
    "    X_train_cleaned = X_train.dropna()\n",
    "    X_val1_cleaned = X_val1.dropna()\n",
    "    X_val2_cleaned = X_val2.dropna()\n",
    "    X_kalman_cleaned = X_kalman.dropna()\n",
    "    X_test_cleaned = X_test.dropna()\n",
    "    \n",
    "    # Drop corresponding rows from y\n",
    "    y_train_cleaned = y_train[X_train_cleaned.index]\n",
    "    y_val1_cleaned = y_val1[X_val1_cleaned.index]\n",
    "    y_val2_cleaned = y_val2[X_val2_cleaned.index]\n",
    "    y_kalman_cleaned = y_kalman[X_kalman_cleaned.index]\n",
    "    y_test_cleaned = y_test[X_test_cleaned.index]\n",
    "    \n",
    "    return (\n",
    "        X_train_cleaned, X_val1_cleaned, X_val2_cleaned, X_kalman_cleaned, X_test_cleaned,\n",
    "        y_train_cleaned, y_val1_cleaned, y_val2_cleaned, y_kalman_cleaned, y_test_cleaned\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val1, X_val2, X_kalman, X_test, y_train, y_val1, y_val2, y_kalman, y_test = drop_nan_from_Xy(*Xy_before_dropnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-1 Baseline Metrics: {'Accuracy': 0.9995236548662986, 'Precision': 0.996769456681351, 'Recall': 0.996769456681351, 'F1': 0.996769456681351, 'AUC': np.float64(0.9982561635907924)}\n",
      "Random Classifier Metrics: {'Accuracy': 0.49749918804806753, 'Precision': 0.07348696963170363, 'Recall': 0.5010279001468428, 'F1': 0.12817430503380917, 'AUC': np.float64(0.4991231132337768)}\n",
      "Rolling Naive Bayes Metrics: {'Accuracy': 0.9985709645988957, 'Precision': 0.9903083700440528, 'Recall': 0.9903083700440528, 'F1': 0.9903083700440528, 'AUC': np.float64(0.9947684907723772)}\n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# Baselines\n",
    "# -----------------\n",
    "\n",
    "# T-1 Baseline\n",
    "y_t1_baseline = X_test[\"target_lag1\"].astype(int)\n",
    "t1_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_t1_baseline),\n",
    "    \"Precision\": precision_score(y_test, y_t1_baseline, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, y_t1_baseline, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, y_t1_baseline, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, y_t1_baseline)\n",
    "}\n",
    "print(\"T-1 Baseline Metrics:\", t1_metrics)\n",
    "\n",
    "# Random Classifier Baseline\n",
    "def random_classifier(y_true, seed=42):\n",
    "    random.seed(seed)\n",
    "    return pd.Series([random.choice([0, 1]) for _ in range(len(y_true))], index=y_true.index)\n",
    "\n",
    "y_random = random_classifier(y_test)\n",
    "random_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_random),\n",
    "    \"Precision\": precision_score(y_test, y_random, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, y_random, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, y_random, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, y_random)\n",
    "}\n",
    "print(\"Random Classifier Metrics:\", random_metrics)\n",
    "\n",
    "# Rolling Naive Bayes Baseline\n",
    "def rolling_naive_bayes(train_series, test_series, window_size):\n",
    "    predictions = []\n",
    "    rolling_buffer = train_series.tail(window_size)\n",
    "\n",
    "    for test_point in test_series:\n",
    "        # Fit Naive Bayes on the rolling buffer\n",
    "        X_train = np.arange(len(rolling_buffer)).reshape(-1, 1)  # Sequential indices as features\n",
    "        y_train = rolling_buffer.values  # Targets\n",
    "\n",
    "        model = GaussianNB()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the test point\n",
    "        X_test = np.array([[len(rolling_buffer)]]).reshape(-1, 1)\n",
    "        prediction = model.predict(X_test)\n",
    "        predictions.append(prediction[0])\n",
    "\n",
    "        # Update rolling buffer\n",
    "        rolling_buffer = pd.concat([rolling_buffer, pd.Series([test_point])], ignore_index=True)\n",
    "        if len(rolling_buffer) > window_size:\n",
    "            rolling_buffer = rolling_buffer.iloc[1:]\n",
    "\n",
    "    return pd.Series(predictions, index=test_series.index)\n",
    "\n",
    "\n",
    "y_rolling_nb = rolling_naive_bayes(pd.concat([y_train, y_val1, y_val2]), y_test, WINDOW_SIZE)\n",
    "rolling_nb_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_rolling_nb),\n",
    "    \"Precision\": precision_score(y_test, y_rolling_nb, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, y_rolling_nb, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, y_rolling_nb, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, y_rolling_nb)\n",
    "}\n",
    "print(\"Rolling Naive Bayes Metrics:\", rolling_nb_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics: {'Accuracy': 0.999263830247916, 'Precision': 0.9967580312407899, 'Recall': 0.9932452276064611, 'F1': 0.9949985289791115, 'AUC': np.float64(0.9987709614947629)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 37\u001b[0m\n\u001b[1;32m     32\u001b[0m rf_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomforest__n_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],  \u001b[38;5;66;03m# Prefixed by 'randomforest__'\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomforest__max_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m]\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     36\u001b[0m rf_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(rf_pipeline, rf_param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mrf_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m rf_grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     40\u001b[0m rf_preds \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    661\u001b[0m         )\n\u001b[0;32m--> 662\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    479\u001b[0m ]\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    198\u001b[0m         X,\n\u001b[1;32m    199\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m~/Dev/Projects/OSA/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# Base Models\n",
    "# -----------------\n",
    "# -----------------\n",
    "# Logistic Regression\n",
    "# -----------------\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logisticregression', LogisticRegression(class_weight='balanced'))  # Handle class imbalance\n",
    "])\n",
    "log_reg_grid = GridSearchCV(log_reg_pipeline, LASSO_PARAM_GRID, cv=5, scoring='roc_auc')\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "log_reg_model = log_reg_grid.best_estimator_\n",
    "\n",
    "log_reg_preds = log_reg_model.predict(X_test)\n",
    "log_reg_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, log_reg_preds),\n",
    "    \"Precision\": precision_score(y_test, log_reg_preds, zero_division=0),  # Avoid warning\n",
    "    \"Recall\": recall_score(y_test, log_reg_preds, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, log_reg_preds, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, log_reg_model.predict_proba(X_test)[:, 1])\n",
    "}\n",
    "print(\"Logistic Regression Metrics:\", log_reg_metrics)\n",
    "\n",
    "# -----------------\n",
    "# Random Forest\n",
    "# -----------------\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('randomforest', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'))  # Handle class imbalance\n",
    "])\n",
    "rf_param_grid = {\n",
    "    \"randomforest__n_estimators\": [50, 100, 200],  # Prefixed by 'randomforest__'\n",
    "    \"randomforest__max_depth\": [None, 10, 20]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_pipeline, rf_param_grid, cv=5, scoring='roc_auc')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, rf_preds),\n",
    "    \"Precision\": precision_score(y_test, rf_preds),\n",
    "    \"Recall\": recall_score(y_test, rf_preds),\n",
    "    \"F1\": f1_score(y_test, rf_preds),\n",
    "    \"AUC\": roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "}\n",
    "print(\"Random Forest Metrics:\", rf_metrics)\n",
    "\n",
    "# -----------------\n",
    "# XGBoost\n",
    "# -----------------\n",
    "# Define the pipeline\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Prefix all hyperparameters for 'xgb' step with 'xgb__'\n",
    "xgb_param_grid = {\n",
    "    \"xgb__n_estimators\": [50, 100, 200],\n",
    "    \"xgb__max_depth\": [3, 5, 7],\n",
    "    \"xgb__learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"xgb__subsample\": [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "xgb_grid = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=5, scoring='roc_auc')\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "xgb_model = xgb_grid.best_estimator_\n",
    "\n",
    "# Predictions and metrics\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "xgb_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, xgb_preds),\n",
    "    \"Precision\": precision_score(y_test, xgb_preds, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, xgb_preds, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, xgb_preds, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, 1])\n",
    "}\n",
    "print(\"XGBoost Metrics:\", xgb_metrics)\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Lasso (Base)\n",
    "# -----------------\n",
    "lasso_base_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scaling for consistent input\n",
    "    ('lasso', LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear'))  # L1 Regularization\n",
    "])\n",
    "lasso_base_param_grid = {\"lasso__C\": np.logspace(-3, 2, 10)}  # Regularization strength\n",
    "\n",
    "lasso_base_grid = GridSearchCV(lasso_base_pipeline, lasso_base_param_grid, cv=5, scoring='roc_auc')\n",
    "lasso_base_grid.fit(X_train, y_train)\n",
    "lasso_base_model = lasso_base_grid.best_estimator_  # Capture the best Lasso model\n",
    "\n",
    "# Predictions and Metrics\n",
    "lasso_base_preds_proba = lasso_base_model.predict_proba(X_test)[:, 1]\n",
    "lasso_base_preds = (lasso_base_preds_proba > 0.5).astype(int)\n",
    "\n",
    "lasso_base_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, lasso_base_preds),\n",
    "    \"Precision\": precision_score(y_test, lasso_base_preds, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, lasso_base_preds, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, lasso_base_preds, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, lasso_base_preds_proba)\n",
    "}\n",
    "print(\"Lasso (Base) Metrics:\", lasso_base_metrics)\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Neural Network Models\n",
    "# -----------------\n",
    "class BinaryNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BinaryNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "def train_nn_with_hyperparams(X_train, y_train, X_val1, y_val1, param_grid):\n",
    "    \"\"\"Grid search for PyTorch NN.\"\"\"\n",
    "    best_params = None\n",
    "    best_auc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for params in product(*param_grid.values()):\n",
    "        hidden_size, lr, num_epochs = params\n",
    "        model = BinaryNN(input_size=X_train.shape[1], hidden_size=hidden_size)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "        X_val1_tensor = torch.tensor(X_val1.values, dtype=torch.float32)\n",
    "        y_val1_tensor = torch.tensor(y_val1.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        # Train\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val1_tensor).flatten().numpy()\n",
    "        auc = roc_auc_score(y_val1, val_outputs)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    return best_model, {\"AUC\": best_auc, \"Best Params\": best_params}\n",
    "\n",
    "# Train and evaluate NN\n",
    "nn_model, nn_metrics = train_nn_with_hyperparams(X_train, y_train, X_val1, y_val1, NN_PARAM_GRID)\n",
    "\n",
    "# Predictions and Metrics for Test Set\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    nn_outputs = nn_model(X_test_tensor).flatten().numpy()\n",
    "nn_preds = (nn_outputs > 0.5).astype(int)\n",
    "\n",
    "nn_test_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, nn_preds),\n",
    "    \"Precision\": precision_score(y_test, nn_preds, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, nn_preds, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, nn_preds, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, nn_outputs)\n",
    "}\n",
    "print(\"Neural Network Test Metrics:\", nn_test_metrics)\n",
    "\n",
    "# -----------------\n",
    "# LSTM Model for Classification\n",
    "# -----------------\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        x = self.sigmoid(self.fc(hidden[-1]))\n",
    "        return x\n",
    "\n",
    "def train_lstm_with_hyperparams(X_train, y_train, X_val1, y_val1, param_grid):\n",
    "    \"\"\"Grid search for LSTM.\"\"\"\n",
    "    best_params = None\n",
    "    best_auc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for params in product(*param_grid.values()):\n",
    "        hidden_size, num_layers, lr, num_epochs = params\n",
    "        model = LSTMClassifier(input_size=X_train.shape[1], hidden_size=hidden_size, num_layers=num_layers)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_seq = torch.tensor(X_train.values.reshape(-1, 1, X_train.shape[1]), dtype=torch.float32)\n",
    "        y_train_seq = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "        X_val1_seq = torch.tensor(X_val1.values.reshape(-1, 1, X_val1.shape[1]), dtype=torch.float32)\n",
    "        y_val1_seq = torch.tensor(y_val1.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        # Train\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_seq)\n",
    "            loss = criterion(outputs, y_train_seq)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val1_seq).flatten().numpy()\n",
    "        auc = roc_auc_score(y_val1, val_outputs)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    return best_model, {\"AUC\": best_auc, \"Best Params\": best_params}\n",
    "\n",
    "# Train and evaluate LSTM\n",
    "lstm_model, lstm_metrics = train_lstm_with_hyperparams(X_train, y_train, X_val1, y_val1, LSTM_PARAM_GRID)\n",
    "\n",
    "# Predictions and Metrics for Test Set\n",
    "X_test_seq = torch.tensor(X_test.values.reshape(-1, 1, X_test.shape[1]), dtype=torch.float32)\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    lstm_outputs = lstm_model(X_test_seq).flatten().numpy()\n",
    "lstm_preds = (lstm_outputs > 0.5).astype(int)\n",
    "\n",
    "lstm_test_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, lstm_preds),\n",
    "    \"Precision\": precision_score(y_test, lstm_preds, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, lstm_preds, zero_division=0),\n",
    "    \"F1\": f1_score(y_test, lstm_preds, zero_division=0),\n",
    "    \"AUC\": roc_auc_score(y_test, lstm_outputs)\n",
    "}\n",
    "print(\"LSTM Test Metrics:\", lstm_test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
